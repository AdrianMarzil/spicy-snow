{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spicy snow counter example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how spicy snow / lievens algorithm might not actually be measuring changes in snow depth as well as we think it does. I hypothesize we are basically accumulating a (elevation dependent) backscatter ratio variability. This elevation dependent backscatter ratio variability is complicated, but likely includes some combination of radar processing affects, radar artifacts, elevation dependent temperature, soil moisture, as well as maybe a little true volume scattering from snow and wet snow effects (ask me about this one, I have some theories), etc. To start testing this hypothesis, I ran the spicy snow algorithm retrieving snow depth over an area that don't actually regularly accumulate snow (mountains just north of phenoix). My hypothesis is that if I get similar snow depth rasters for two different mountain ranges (one with true snow, and one without true snow), the physics and physical interpretation of this snow depth method should be in question. I set fake ims data (0 before the accumulation season, 4 in the accumulation season, and 0 afterwards to trick the algorithm into thinking there is snow present during the accumulation season), ran the algorithm, and found a believeable \"snow depth\". The \"snow depth\" raster time series is shown below in the facetgrid plot, and below that is the mean \"snow depth\" in each elevation bin over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pystac-client\n",
    "!pip install -q planetary-computer\n",
    "!pip install -q odc-stac\n",
    "!pip install -q xarray-spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../spicy-snow/')\n",
    "import os\n",
    "from spicy_snow.retrieval import retrieve_snow_depth, retrieval_from_parameters\n",
    "from spicy_snow.IO.user_dates import get_input_dates\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely import geometry\n",
    "import contextily as ctx \n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import odc.stac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xrspatial.multispectral as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose mountainous area with usually no snow during accumulation season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson of aoi\n",
    "aoi = 'north_of_pheonix'\n",
    "area_gdf = gpd.read_file(f'data/{aoi}.geojson')\n",
    "area = list(area_gdf.geometry)[0].envelope # convert feature to box for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aoi\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "area_gdf.boundary.plot(ax=ax, color='r')\n",
    "\n",
    "ctx.add_basemap(ax=ax, crs=area_gdf.crs, source=ctx.providers.OpenTopoMap)\n",
    "ax.set_title('AOI location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve snow depth per usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will generate a tuple of dates from the previous August 1st to this date\n",
    "dates = get_input_dates('2021-07-31')\n",
    "\n",
    "# define output directory and file name\n",
    "out_nc = Path(f'data/{aoi}_sd_{dates[0]}_{dates[1]}.nc').expanduser()\n",
    "\n",
    "if os.path.isfile(out_nc):\n",
    "    spicy_ds = xr.open_mfdataset(out_nc)\n",
    "    print(f'Opening dataset at {out_nc}')\n",
    "else:\n",
    "    spicy_ds = retrieve_snow_depth(area = area, dates = dates, \n",
    "                                work_dir = Path('/tmp/er_test/').expanduser(), \n",
    "                                job_name = f'sd_{dates[0]}_{dates[1]}',\n",
    "                                existing_job_name = f'{aoi}_sd_{dates[0]}_{dates[1]}',\n",
    "                                debug=False,\n",
    "                                outfp=out_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add a dem layer and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in cop 30 m dem\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\",modifier=planetary_computer.sign_inplace)\n",
    "search = catalog.search(collections=\"cop-dem-glo-30\", bbox=spicy_ds.rio.bounds())\n",
    "items = list(search.get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_raster_all = odc.stac.load(items, bbox=spicy_ds.rio.bounds()).squeeze()\n",
    "dem_raster = dem_raster_all['data']\n",
    "dem_raster = dem_raster.rio.set_nodata(np.NaN)\n",
    "\n",
    "dem = dem_raster.rio.reproject_match(spicy_ds)\n",
    "spicy_ds['dem'] = dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_ds['dem'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's check the included ims data to check if there is truly no snow in our aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_ds['ims'].plot(col='time',col_wrap=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's confirm with optical imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    bbox=spicy_ds.rio.bounds(),\n",
    "    datetime=f'{dates[0]}/{dates[1]}',\n",
    "    collections=\"sentinel-2-l2a\")\n",
    "\n",
    "items = list(search.get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (odc.stac.load(\n",
    "        items,\n",
    "        bands=[\"B04\", \"B03\", \"B02\"],  # red, green, blue\n",
    "        like=dem_raster_all)\n",
    "    .where(lambda x: x > 0, other=np.nan)  # sentinel-2 uses 0 as nodata\n",
    "    .assign_coords(band=lambda x: x.common_name.rename(\"band\"))  # use common names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = data.groupby(\"time.week\").median()#.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ms.true_color(*x) for x in monthly]\n",
    "images = xr.concat(images, dim=\"time\")\n",
    "\n",
    "g = images.plot.imshow(x=\"x\", y=\"y\", rgb=\"band\", col=\"time\", col_wrap=5, figsize=(6, 8))\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we will replace the true ims data with fake ims data based on a fake accumulation season and visualize the new ims data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_accumulation_season_start = '2020-10-15'\n",
    "fake_accumulation_season_end = '2021-07-01'\n",
    "spicy_ds['ims'] = xr.where((spicy_ds['ims'].time<pd.to_datetime(fake_accumulation_season_start)) | (spicy_ds['ims'].time>pd.to_datetime(fake_accumulation_season_end)),xr.full_like(spicy_ds['ims'].isel(time=0),0),xr.full_like(spicy_ds['ims'].isel(time=0),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_ds['ims'].plot(col='time',col_wrap=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we will rerun snow index and snow depth calculations with the fake ims data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_ds = retrieval_from_parameters(spicy_ds, A = 2.5, B = 0.2, C = 0.55, wet_snow_thresh = -2, freezing_snow_thresh = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"snow depth\" raster time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_ds['snow_depth'].plot(col='time',col_wrap=10,cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"snow depth\" time series binned by elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(24,7))\n",
    "spicy_ds.groupby_bins(group='dem',bins=30).mean()['snow_depth'].plot(ax=ax,cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy_snow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
