{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search as asf\n",
    "import pandas as pd\n",
    "import shapely.geometry\n",
    "import xarray\n",
    "import sys\n",
    "sys.path.append('../../spicy-snow/')\n",
    "from download.sentinel1 import s1_img_search#, download_s1_imgs\n",
    "\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = '/Users/zachkeskinen/miniconda3/pkgs/proj-9.1.0-hf909084_1/share/proj'\n",
    "\n",
    "import pyproj\n",
    "pyproj.datadir.set_data_dir('/Users/zachkeskinen/miniconda3/pkgs/proj-9.1.0-hf909084_1/share/proj')\n",
    "pyproj._pyproj_global_context_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "area = box(-114.4, 43, -114.3, 43.1)\n",
    "dates = ('2019-12-28', '2020-02-02')\n",
    "search_result = s1_img_search(area, dates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Download from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyp3_sdk.exceptions import AuthenticationError\n",
    "import hyp3_sdk as sdk\n",
    "try:\n",
    "    # .netrc\n",
    "    hyp3 = sdk.HyP3()\n",
    "except AuthenticationError:\n",
    "    # prompt for password\n",
    "    hyp3 = sdk.HyP3(prompt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_jobs = hyp3.find_jobs(name = 'cloud-download-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granules = search_result['properties.sceneName'].iloc[:2]\n",
    "\n",
    "rtc_jobs = sdk.Batch()\n",
    "for g in granules:\n",
    "    # https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_rtc_job\n",
    "    rtc_jobs += hyp3.submit_rtc_job(g, name = 'cloud-download-test', include_inc_map = True,\\\n",
    "        scale = 'amplitude', dem_matching = False, resolution = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "pbar = tqdm(total = len(rtc_jobs))\n",
    "while not rtc_jobs.complete():\n",
    "    # to get updated information\n",
    "    pbar.update(len(rtc_jobs.filter_jobs(succeeded=True, running=False, failed=True)))\n",
    "    rtc_jobs = hyp3.refresh(rtc_jobs)\n",
    "pbar.close()\n",
    "    \n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "print(f'Number of succeeded jobs: {len(succeeded_jobs)}')\n",
    "failed_jobs = rtc_jobs.filter_jobs(succeeded=False, running=False, failed=True)\n",
    "print(f'Number of failed jobs: {len(failed_jobs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = rtc_jobs[0].files[0]['url']\n",
    "vv_url = u.replace('.zip', '_VV.tif')\n",
    "vh_url = u.replace('.zip', '_VH.tif')\n",
    "inc_url = u.replace('.zip', '_inc_map.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = min(int(count*block_size*100/total_size),100)\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                    (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "from os.path import basename, exists\n",
    "def url_download(url, out_fp, overwrite = False):\n",
    "    if not exists(out_fp) or overwrite == True:\n",
    "        print(f'Downloading {basename(out_fp)}.')\n",
    "        urlretrieve(url, out_fp, reporthook)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray as rxa\n",
    "das = []\n",
    "for i, job in enumerate(rtc_jobs[:2]):\n",
    "    u = job.files[0]['url']\n",
    "    granule = job.job_parameters['granules'][0]\n",
    "    urls = {}\n",
    "    urls[f'{granule}_VV'] = u.replace('.zip', '_VV.tif')\n",
    "    urls[f'{granule}_VH'] = u.replace('.zip', '_VH.tif')\n",
    "    urls[f'{granule}_inc'] = u.replace('.zip', '_inc_map.tif')\n",
    "    for j, (name, url) in enumerate(urls.items()):\n",
    "        url_download(url, f'data/{name}.tif')\n",
    "        img = rxa.open_rasterio(f'data/{name}.tif').rio.clip([area], 'EPSG:4326')\n",
    "        img = img.rio.reproject('EPSG:4326')\n",
    "        band_name = name.replace(f'{granule}_', '')\n",
    "        img = img.assign_coords(time = pd.to_datetime(granule.split('_')[4]))\n",
    "        if j == 0:\n",
    "            da = img.assign_coords(band = [band_name])\n",
    "            da.attrs[\"long_name\"] = granule\n",
    "            da.attrs[\"mission\"] = granule.split('_')[0]\n",
    "            da.attrs[\"mode\"] = granule.split('_')[1]\n",
    "            da.attrs[\"product-type\"] = granule.split('_')[2][:3]\n",
    "            da.attrs[\"resolution\"] = granule.split('_')[2][3]\n",
    "            da.attrs[\"processing-level\"] = granule.split('_')[3][0]\n",
    "            da.attrs[\"product-class\"] = granule.split('_')[3][1]\n",
    "            da.attrs[\"polarization-type\"] = granule.split('_')[3][2:]\n",
    "            da.attrs[\"start-time\"] = pd.to_datetime(granule.split('_')[4])\n",
    "            da.attrs[\"end-time\"] = pd.to_datetime(granule.split('_')[5])\n",
    "            da.attrs[\"absolute-orbit\"] = granule.split('_')[6]\n",
    "            da.attrs[\"take-id\"] = granule.split('_')[7]\n",
    "            da.attrs[\"unique-id\"] = granule.split('_')[8]\n",
    "        else:\n",
    "            da = xr.concat([da, img.assign_coords(band = [band_name])], dim = 'band')\n",
    "    das.append(da)\n",
    "da = xr.concat(das, dim = 'time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing results between sentinel sat and asf_search. Both seem the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = shapely.geometry.box(43, 6, 43.1, 6.1)\n",
    "dates = ('2018-12-28T00:00:00.000Z', '2020-01-02T00:00:00.000Z')\n",
    "search_results = asf.geo_search(platform = [asf.PLATFORM.SENTINEL1], intersectsWith = area.wkt,\\\n",
    "        start = dates[0], end = dates[1], processingLevel = asf.PRODUCT_TYPE.GRD_HD)\n",
    "print(len(search_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "dates = ('2018-12-28T00:00:00.000Z', '2020-01-02T00:00:00.000Z')\n",
    "api = SentinelAPI('zachkeskinen', 'DR1seuss')\n",
    "footprint = area.wkt\n",
    "products = api.query(footprint, platformname = 'Sentinel-1', producttype = 'GRD', beginposition = dates,\n",
    "                     polarisationmode = 'VV+VH', limit=1000)\n",
    "print(len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "area = box(-114.4, 43, -114.3, 43.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.bounds[3] < 90\n",
    "area.bounds[1] > 0\n",
    "area.bounds[2] < 180\n",
    "area.bounds[0] > -180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55f2b22363d79254ff041d13471de54e352f3ae9dfa1886ee2b85fe903b5a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
