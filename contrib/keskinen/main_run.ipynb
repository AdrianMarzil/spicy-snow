{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load up the saved dataset\n",
    "import pickle\n",
    "# fp = '/Users/zachkeskinen/Documents/spicy-snow/tests/test_data/2_img_ds'\n",
    "fp = '/Users/zachkeskinen/Documents/spicy-snow/data/10_img_dB.pkl'\n",
    "# fp = '/Users/zachkeskinen/Documents/spicy-snow/data/main_test_proc.pkl'\n",
    "with open(fp, 'rb') as f:\n",
    "    ds = pickle.load(f)\n",
    "\n",
    "# add module to path so python can import it. This is the directory with \n",
    "# the __init__.py file in it to let python know this is a module.\n",
    "import sys\n",
    "sys.path.append('/Users/zachkeskinen/Documents/spicy-snow/spicy_snow')\n",
    "\n",
    "from processing.snow_index import calc_prev_snow_index, calc_snow_index, find_repeat_interval, calc_delta_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['fcf'] = ds['fcf']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = calc_delta_gamma(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add module to path so python can import it. This is the directory with \n",
    "# the __init__.py file in it to let python know this is a module.\n",
    "import sys\n",
    "sys.path.append('/Users/zachkeskinen/Documents/spicy-snow/spicy_snow')\n",
    "\n",
    "from processing.snow_index import calc_prev_snow_index, calc_snow_index, find_repeat_interval\n",
    "\n",
    "backscatter = np.random.randn(10, 10, 3, 3)\n",
    "deltaGamma = np.random.randn(10, 10 , 3)\n",
    "times = [np.datetime64(t) for t in ['2020-01-01', '2020-01-07', '2020-01-14']]\n",
    "x = np.linspace(0, 9, 10)\n",
    "y = np.linspace(10, 19, 10)\n",
    "lon, lat = np.meshgrid(x, y)\n",
    "\n",
    "test_ds = xr.Dataset(\n",
    "    data_vars = dict(\n",
    "        s1 = ([\"x\", \"y\", \"time\", \"band\"], backscatter),\n",
    "        deltaGamma = ([\"x\", \"y\", \"time\"], deltaGamma)\n",
    "    ),\n",
    "\n",
    "    coords = dict(\n",
    "        lon = ([\"x\", \"y\"], lon),\n",
    "        lat = ([\"x\", \"y\"], lat),\n",
    "        band = ['VV', 'VH', 'inc'],\n",
    "        time = times,\n",
    "        relative_orbit = ([\"time\"], [24, 24, 24])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1= calc_snow_index(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds1['snow_index'].isel(time = 0).isnull().sum() == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1['snow_index'].isel(time = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1['deltaGamma'].isel(time = 1) + ds1['deltaGamma'].isel(time = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(ds1['snow_index'].isel(time = 1), ds1['deltaGamma'].isel(time = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1['deltaGamma'].isel(time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1['snow_index'].isel(time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prev_snow_index(dataset: xr.Dataset, current_time: np.datetime64, repeat: pd.Timedelta) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Calculate previous snow index for +/- 5 days (6 day timestep) or +/- 11 days \n",
    "    (12 day time step) from previous time step (6/12 days)'s snow index\n",
    "\n",
    "    SI (i, t_previous) = sum (t_pri - 5/11 days, t_pri + 5/11 days)(SI * weights) / sum(weights)\n",
    "\n",
    "    with:\n",
    "        w_k: as the inverse distance in time from t_previous so for 6-days: \n",
    "        wgts=repmat(win+1-abs([-win:win]),dim,1); [1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "    Args:\n",
    "    dataset: dataset of sentinel-1 images with 'snow-index' data variable\n",
    "    current_time: the current image date\n",
    "    repeat: is this region capturing s1 images every 6 or 12 days\n",
    "\n",
    "    Returns:\n",
    "    prev_si: the weighted average of previous snow indexes\n",
    "    \"\"\"\n",
    "    # calculate how many days ago we are centering previous snow indexes (6 or 12 days)\n",
    "    t_prev = current_time - repeat\n",
    "    # get slice of +- 5 or +- 11 days depending on repeat interval\n",
    "    t_oldest, t_youngest = pd.to_datetime(t_prev - (repeat - pd.Timedelta('1 day'))) , pd.to_datetime(t_prev + (repeat - pd.Timedelta('1 day')))\n",
    "    # slice dataset to get all images in previous period\n",
    "    prev = dataset.sel(time = slice(t_oldest, t_youngest))\n",
    "    # calculate weights based on days between centered date and image acquistions\n",
    "    wts = repeat.days - np.abs([int((t - t_prev).days) for t in prev.time.values])\n",
    "    # calculate previous snow index weighted by time from last acquistion\n",
    "    prev_si = (prev['snow_index']*wts).sum(dim = 'time')/np.sum(wts)\n",
    "\n",
    "    return prev_si\n",
    "\n",
    "def calc_snow_index(dataset: xr.Dataset, inplace: bool = False) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate snow index for each time step from previous time steps' snow index\n",
    "    weights, and current delta-gamma.\n",
    "\n",
    "    SI (i, t) = SI (i, t_previous) + delta-gamma (i, t)\n",
    "\n",
    "    with SI (i, t_previous) as:\n",
    "        SI (i, t_previous) = sum (t_pri - 5/11 days, t_pri + 5/11 days)(SI * weights) / sum(weights)\n",
    "\n",
    "    Args:\n",
    "    dataset: Xarray Dataset of sentinel images with delta-gamma\n",
    "    inplace: operate on dataset in place or return copy\n",
    "\n",
    "    Returns:\n",
    "    dataset: Xarray Dataset of sentinel images with snow-index added as band\n",
    "    \"\"\"\n",
    "    # check inplace flag\n",
    "    if not inplace:\n",
    "        dataset = dataset.copy(deep=True)\n",
    "\n",
    "    # set all snow index to 0 to start\n",
    "    dataset['snow_index'] = xr.zeros_like(dataset['deltaGamma'])\n",
    "\n",
    "    # find repeat interval of dataset\n",
    "    repeat = find_repeat_interval(dataset)\n",
    "\n",
    "    # iterate through time steps\n",
    "    for ct in dataset.time.values:\n",
    "        # calculate previous snow index\n",
    "        prev_si = calc_prev_snow_index(dataset, ct, repeat)\n",
    "        # add deltaGamma to previous snow inded\n",
    "        dataset['snow_index'].loc[dict(time = ct)] = prev_si + dataset['deltaGamma'].sel(time = ct)\n",
    "    \n",
    "    if not inplace:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backscatter = np.random.randn(10, 10, 6, 3)\n",
    "deltaGamma = np.random.randn(10, 10 , 6)\n",
    "times = [np.datetime64(t) for t in ['2020-01-01','2020-01-02', '2020-01-07','2020-01-08', '2020-01-14', '2020-01-15']]\n",
    "x = np.linspace(0, 9, 10)\n",
    "y = np.linspace(10, 19, 10)\n",
    "lon, lat = np.meshgrid(x, y)\n",
    "\n",
    "test_ds = xr.Dataset(\n",
    "    data_vars = dict(\n",
    "        s1 = ([\"x\", \"y\", \"time\", \"band\"], backscatter),\n",
    "        deltaGamma = ([\"x\", \"y\", \"time\"], deltaGamma),\n",
    "        snow_index = ([\"x\", \"y\", \"time\"], np.zeros_like(deltaGamma)),\n",
    "    ),\n",
    "\n",
    "    coords = dict(\n",
    "        lon = ([\"x\", \"y\"], lon),\n",
    "        lat = ([\"x\", \"y\"], lat),\n",
    "        band = ['VV', 'VH', 'inc'],\n",
    "        time = times,\n",
    "        relative_orbit = ([\"time\"], [24, 1, 24, 1, 24, 1])))\n",
    "\n",
    "ds = calc_snow_index(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['snow_index'].isel(time = 1)*5/(6+5) + ds['deltaGamma'].isel(time = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ds['snow_index'].isel(time = 2) == ds['snow_index'].isel(time = 1)*5/(6+5) + ds['deltaGamma'].isel(time = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55f2b22363d79254ff041d13471de54e352f3ae9dfa1886ee2b85fe903b5a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
