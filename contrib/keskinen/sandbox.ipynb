{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shapely\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxa\n",
    "\n",
    "# Add main repo to path\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "sys.path.append(expanduser('../../'))\n",
    "\n",
    "from spicy_snow import retrieve_snow_depth\n",
    "\n",
    "from spicy_snow.IO.user_dates import get_input_dates\n",
    "from spicy_snow.processing.s1_preprocessing import merge_partial_s1_images\n",
    "from spicy_snow.download.sentinel1 import combine_s1_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(Path('~/Desktop/spicy-lowman.nc').expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = shapely.geometry.box(-117, 43, -113, 46)\n",
    "\n",
    "# results dictionary to send to next step\n",
    "dataArrays = {}\n",
    "\n",
    "for i, fp in enumerate(sorted(Path('~/Desktop/imgs').expanduser().glob('*VV.tif'))):\n",
    "    if i < 6:\n",
    "        urls = {}\n",
    "        granule = fp.stem.replace('_VV', '')\n",
    "        if i == 0:\n",
    "            first_granule = granule\n",
    "        urls[fp.stem] = fp\n",
    "        urls[fp.stem.replace('VV', 'VH')] = str(fp.parents[0]) + '/' + fp.name.replace('VV', 'VH')\n",
    "        urls[fp.stem.replace('VV', 'inc')] = str(fp.parents[0]) + '/' + fp.name.replace('VV', 'inc')\n",
    "        imgs = []\n",
    "        for name, url in urls.items():\n",
    "            # download url to a tif file\n",
    "            # url_download(url, join(outdir, f'{name}.tif'), verbose = False)\n",
    "\n",
    "            # open image in xarray\n",
    "            img = rxa.open_rasterio(url, masked = True)\n",
    "\n",
    "            # reproject to WGS84\n",
    "            img = img.rio.reproject('EPSG:4326')\n",
    "\n",
    "            # clip to user specified area\n",
    "            img = img.rio.clip_box(*area.bounds)\n",
    "\n",
    "            # pad to area\n",
    "            img = img.rio.pad_box(*area.bounds)\n",
    "\n",
    "            # create band name\n",
    "            band_name = name.replace(f'{granule}_', '')\n",
    "\n",
    "            # add band to image\n",
    "            img = img.assign_coords(band = [band_name])\n",
    "\n",
    "            # coarsen image\n",
    "            img = img.coarsen(x = 3, boundary = 'trim').mean().coarsen(y = 3, boundary = 'trim').mean()\n",
    "\n",
    "            # add named band image to 3 image stack\n",
    "            imgs.append(img)\n",
    "\n",
    "        # concat VV, VH, and inc into one xarray DataArray\n",
    "        da = xr.concat(imgs, dim = 'band')\n",
    "\n",
    "        # we need to reproject each image to match the first image to make CRSs work\n",
    "        if dataArrays:\n",
    "            da = da.rio.reproject_match(dataArrays[first_granule])\n",
    "\n",
    "        # add img to downloaded dataArrays list with granule as key\n",
    "        dataArrays[granule] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = combine_s1_images(dataArrays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55f2b22363d79254ff041d13471de54e352f3ae9dfa1886ee2b85fe903b5a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
