{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/zachkeskinen/Documents/spicy-snow/')\n",
    "from spicy_snow.download.snowex_lidar import download_dem\n",
    "\n",
    "import pickle\n",
    "with open('/Users/zachkeskinen/Documents/spicy-snow/SnowEx-Data/Cameron_test.pkl', 'rb') as f:\n",
    "    ds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in ds.time:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{\"Cameron\"}_{(date).dt.strftime(\"%y-%m-%d\").values}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_site_ds(site):\n",
    "    ds = xr.Dataset()\n",
    "\n",
    "    for img_type in ['SD', 'VH', 'DEM']:\n",
    "        files = glob(join(lidar_dir, f'*_{img_type}_*_{site}_*.tif'))\n",
    "        assert files, f\"No files found for {img_type} at {site_name}\"\n",
    "        \n",
    "        imgs = []\n",
    "        for f in files:\n",
    "            print(f)\n",
    "            date = pd.to_datetime(basename(f).split('_')[-2])\n",
    "\n",
    "            img = rxa.open_rasterio(f, masked = True)\n",
    "\n",
    "            img = img.squeeze(dim = 'band')\n",
    "            \n",
    "            img = img.expand_dims(time = [date])\n",
    "\n",
    "            imgs.append(img)\n",
    "    \n",
    "        ds['lidar-' + img_type.lower()] = xr.concat(imgs, dim = 'time')\n",
    "\n",
    "    ds = ds.rio.reproject('EPSG:4326')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join, basename\n",
    "import os\n",
    "lidar_dir = '/Users/zachkeskinen/Documents/spicy-snow/data/lidar'\n",
    "\n",
    "sites = {'USCOCP': 'Cameron', 'USCOFR': 'Frasier', 'USIDBS': 'Banner', 'USIDDC': 'Dry_Creek',\n",
    "         'USIDMC': 'Mores', 'USUTLC': 'Little_Cottonwood'}\n",
    "\n",
    "sites = {'USIDDC': 'Dry_Creek'}\n",
    "# sites = {'USIDBS': 'Banner'}\n",
    "\n",
    "for site, site_name in sites.items():\n",
    "\n",
    "    lidar_ds_dc = make_site_ds(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in ds.time:\n",
    "    if date.dt.month < 8:\n",
    "        last_year = date.dt.year - 1\n",
    "        date1 = pd.to_datetime(f'{int(date.dt.year - 1)}-08-01')\n",
    "    else:\n",
    "        date1 = pd.to_datetime(f'{int(date.dt.year)}-08-01')\n",
    "    print((date1, pd.to_datetime(date.values)))\n",
    "    date1 = date - pd.Timedelta('26 days')\n",
    "\n",
    "    # spicy_ds = retrieve_snow_depth(area = area, dates = (date1, pd.to_datetime(date.values)), work_dir = '../data/', job_name = f'spicy-{site}')\n",
    "    import pickle\n",
    "    with open('/Users/zachkeskinen/Documents/spicy-snow/data/banner_lidar.pkl', 'rb') as f:\n",
    "        spicy_ds = pickle.load(f)\n",
    "    \n",
    "    lidar_ds.rio.reproject_match(spicy_ds)\n",
    "\n",
    "    # ds = xr.merge([spicy_ds, lidar_ds], combine_attrs = 'drop_conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_ds['sd'].rio.write_nodata(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_ds_re = lidar_ds.rio.reproject_match(spicy_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([spicy_ds, nanlidards], combine_attrs = 'drop_conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanlidards = lidar_ds_re.where(lidar_ds_re < 1000).where(lidar_ds_re > -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanlidards['sd'].rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[['sd', 'vh', 'dem', 'snow_depth', 's1']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55f2b22363d79254ff041d13471de54e352f3ae9dfa1886ee2b85fe903b5a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
