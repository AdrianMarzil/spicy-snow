{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "x = np.linspace(0, 9, 10)\n",
    "y = np.linspace(10, 19, 10)\n",
    "lon, lat = np.meshgrid(x, y)\n",
    "times = pd.date_range(\"2020-01-01\", end = '2020-12-31', freq = '6D')\n",
    "n = len(times)\n",
    "data = np.random.randn(10,10, n)\n",
    "\n",
    "ros = np.resize([1, 24], (n))\n",
    "platforms = np.resize(['S1A', 'S1B', 'S1B', 'S1A'], (n))\n",
    "direction = np.resize(['ascending', 'descending'], (n))\n",
    "\n",
    "ds = xr.Dataset(data_vars= dict(\n",
    "    data = ([\"x\", \"y\", \"time\"], data)\n",
    "        ),\n",
    "    coords = dict(\n",
    "                        lon = ([\"x\", \"y\"], lon),\n",
    "                        lat = ([\"x\", \"y\"], lat),\n",
    "                        time = times,\n",
    "                        relative_orbit = ([\"time\"], ros),\n",
    "                        platform = ([\"time\"], platforms),\n",
    "                        flight_dir = ([\"time\"], direction)) \n",
    "        \n",
    "    )\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/zachkeskinen/Documents/spicy-snow/')\n",
    "from spicy_snow.processing.s1_preprocessing import subset_s1_images, merge_s1_subsets\n",
    "\n",
    "import pickle\n",
    "with open('/Users/zachkeskinen/Documents/spicy-snow/tests/test_data/search_result', 'rb') as f:\n",
    "    ds = pickle.load(f)\n",
    "# ds = ds.isel(time = slice(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "\n",
    "hyp3 = sdk.HyP3()\n",
    "\n",
    "# gather granules to submit to the hyp3 pipeline\n",
    "granules = 'S1B_IW_GRDH_1SDV_20200201T013528_20200201T013553_020069_025FB3_6D5E'\n",
    "\n",
    "# create a new hyp3 batch to hold submitted jobs\n",
    "rtc_jobs = sdk.Batch()\n",
    "\n",
    "rtc_jobs += hyp3.submit_rtc_job(granules, name = 'db test', include_inc_map = True,\\\n",
    "    scale = 'decibel', dem_matching = False, resolution = 30)\n",
    "\n",
    "# warn user this may take a few hours for big jobs\n",
    "print(f'Watching {len(rtc_jobs)} jobs. This may take a while...')\n",
    "\n",
    "# have hyp3 watch and update progress bar every 60 seconds\n",
    "hyp3.watch(rtc_jobs)\n",
    "\n",
    "# refresh jobs list with successes and failures\n",
    "rtc_jobs = hyp3.refresh(rtc_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spicy_snow.utils.download import url_download\n",
    "import rioxarray as rxa\n",
    "\n",
    "u = rtc_jobs[0].files[0]['url']\n",
    "\n",
    "# create dictionary to hold cloud url from .zip url\n",
    "# this lets us download only VV, VH, inc without getting other data from zip\n",
    "urls = {}\n",
    "urls[f'{granules}_VV'] = u.replace('.zip', '_VV.tif')\n",
    "\n",
    "\n",
    "# download url to a tif file\n",
    "url_download(u.replace('.zip', '_VV.tif'), './vv_db.tif', verbose = False)\n",
    "\n",
    "# open image in xarray\n",
    "img = rxa.open_rasterio('./vv_db.tif', masked = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55f2b22363d79254ff041d13471de54e352f3ae9dfa1886ee2b85fe903b5a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
