{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Main Program: Spicy Snow (MacBook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expanduser\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(expanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspicy_snow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m retrieve_snow_depth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspicy_snow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mIO\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_dates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_input_dates\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/VSCode/spicy-snow/contrib/marziliano/../../spicy_snow/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrieval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m retrieve_snow_depth\n",
      "File \u001b[0;32m~/Documents/VSCode/spicy-snow/contrib/marziliano/../../spicy_snow/retrieval.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m join\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Add main repo to path\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "sys.path.append(expanduser('../../'))\n",
    "\n",
    "from spicy_snow import retrieve_snow_depth\n",
    "from spicy_snow.IO.user_dates import get_input_dates\n",
    "\n",
    "import shapely\n",
    "\n",
    "# Provide bounding box (EPSG:4326 user-provided coordinates)\n",
    "area = shapely.geometry.box(-106.9, 36.9, -106.4, 37.4)\n",
    "\n",
    "# Get tuple of dates. Provided date is ending date and start date is always prior August 1st\n",
    "dates = get_input_dates(\"2024-06-01\", \"2023-11-01\")\n",
    "\n",
    "# Function to actually get data, run processing, returns xarray dataset w/ daily time dimension\n",
    "#s1_sd = get_s1_snow_depth(area, dates, work_dir = './contrib/data/BPR_retrieval/')\n",
    "# s1_sd = retrieve_snow_depth(area, dates, work_dir = 'Users/Adrian/Desktop/BPR_retrieval/')\n",
    "s1_sd = retrieve_snow_depth(area, dates, work_dir = '/Users/marzi/Desktop/SpicySnow/')\n",
    "# s1_sd = retrieve_snow_depth(area, dates, work_dir = './BPR_retrieval/')\n",
    "\n",
    "# work_dir will be created if not present \n",
    "# optional keyword ideas: job_name, fitting parameters (A, B, C), exisiting_job_name, outfp\n",
    "# `outfp = './idaho_ret.nc` will output datset to netcdf\n",
    "\n",
    "# plot first day of 2020 to check data quality\n",
    "# s1_sd.sel(time = \"2022-01-01\").plot()\n",
    "\n",
    "# save as pickle file\n",
    "# dump completed dataset to data directory\n",
    "# with open('./BPR_retrieval/spicy_test.pkl', 'wb') as f:\n",
    "    # pickle.dump(ds, f)\n",
    "\n",
    "#s1_sd.to_netcdf(f'./BPR_snd2022.nc')\n",
    "s1_sd.to_netcdf(f'/Users/marzi/Desktop/BPR_snd2024.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear temp files ... (MacBook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear temporary files\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "# Imput directory\n",
    "folder = '/Users/marzi/Desktop/SpicySnow/tmp'\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "print('tmp folder cleared!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Main Program: Spicy Snow (PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Add main repo to path\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "sys.path.append(expanduser('../../'))\n",
    "\n",
    "from spicy_snow import retrieve_snow_depth\n",
    "from spicy_snow.IO.user_dates import get_input_dates\n",
    "\n",
    "import shapely\n",
    "\n",
    "# Provide bounding box (EPSG:4326 user-provided coordinates)\n",
    "area = shapely.geometry.box(-106.9, 36.9, -106.4, 37.4)\n",
    "\n",
    "# Get tuple of dates. Provided date is ending date and start date is always prior August 1st\n",
    "dates = get_input_dates(\"2024-06-01\", \"2023-11-01\")\n",
    "\n",
    "# Function to actually get data, run processing, returns xarray dataset w/ daily time dimension\n",
    "#s1_sd = get_s1_snow_depth(area, dates, work_dir = './contrib/data/BPR_retrieval/')\n",
    "# s1_sd = retrieve_snow_depth(area, dates, work_dir = 'Users/Adrian/Desktop/BPR_retrieval/')\n",
    "s1_sd = retrieve_snow_depth(area, dates, work_dir = 'C:/Users/marzi/Desktop/SpicySnow/')\n",
    "# s1_sd = retrieve_snow_depth(area, dates, work_dir = './BPR_retrieval/')\n",
    "\n",
    "# work_dir will be created if not present \n",
    "# optional keyword ideas: job_name, fitting parameters (A, B, C), exisiting_job_name, outfp\n",
    "# `outfp = './idaho_ret.nc` will output datset to netcdf\n",
    "\n",
    "# plot first day of 2020 to check data quality\n",
    "# s1_sd.sel(time = \"2022-01-01\").plot()\n",
    "\n",
    "# save as pickle file\n",
    "# dump completed dataset to data directory\n",
    "# with open('./BPR_retrieval/spicy_test.pkl', 'wb') as f:\n",
    "    # pickle.dump(ds, f)\n",
    "\n",
    "#s1_sd.to_netcdf(f'./BPR_snd2022.nc')\n",
    "s1_sd.to_netcdf(f'C:/Users/marzi/Desktop/BPR_snd2024.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear temp files ... (PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear temporary files\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "# Imput directory\n",
    "folder = 'C:/Users/marzi/Desktop/SpicySnow/tmp'\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "print('tmp folder cleared!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES\n",
    "# From README file ...\n",
    "\n",
    "# Function to actually get data, run processing, returns xarray dataset w/ daily time dimension\n",
    "s1_sd = get_s1_snow_depth(area, dates, work_dir = './idaho_retrieval/)\n",
    "# Should 'get_s1_snow_depth' be 'retrieve_snow_depth'?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy-snow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
